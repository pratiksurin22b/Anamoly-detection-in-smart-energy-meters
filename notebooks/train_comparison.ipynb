{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# RF vs LSTM Comparison on 15-min Relative Dataset\\n\\n\",\n",
    "    \"This notebook runs the two core experiments:\\n\\n\",\n",
    "    \"- **Experiment 1 (Edge)**: Random Forest on single 15-minute blocks.\\n\",\n",
    "    \"- **Experiment 2 (Cloud)**: LSTM on 24-hour sequences of 15-minute blocks.\\n\\n\",\n",
    "    \"The goal is to show that:\\n\",\n",
    "    \"- RF is strong on **fault (3)** detection and overall accuracy,\\n\",\n",
    "    \"- LSTM improves **fraud (2)** detection by using temporal context.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.train_models import (\\n\",\n",
    "    \"    load_15min_relative,\\n\",\n",
    "    \"    make_train_val_test_split,\\n\",\n",
    "    \"    prepare_block_features,\\n\",\n",
    "    \"    train_random_forest_edge,\\n\",\n",
    "    \"    make_sequences,\\n\",\n",
    "    \"    train_lstm_cloud,\\n\",\n",
    "    \")\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data overview\\n\\n\",\n",
    "    \"Load the 15-minute relative dataset and check label distribution.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df = load_15min_relative('house_1')\\n\",\n",
    "    \"df.head()\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"label_counts = df['label_rel'].value_counts().sort_index()\\n\",\n",
    "    \"label_percent = (label_counts / label_counts.sum() * 100).round(2)\\n\",\n",
    "    \"label_counts, label_percent\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Experiment 1 \u0013 Random Forest (Edge benchmark)\\n\\n\",\n",
    "    \"We re-use the helper from `src.train_models` and also capture per-class accuracy.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_train, df_val, df_test = make_train_val_test_split(df)\\n\",\n",
    "    \"X_train, y_train, feature_cols = prepare_block_features(df_train)\\n\",\n",
    "    \"X_test, y_test, _ = prepare_block_features(df_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
    "    \"X_test_scaled = scaler.transform(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"rf = RandomForestClassifier(\\n\",\n",
    "    \"    n_estimators=200,\\n\",\n",
    "    \"    max_depth=None,\\n\",\n",
    "    \"    n_jobs=-1,\\n\",\n",
    "    \"    random_state=42,\\n\",\n",
    "    \"    class_weight='balanced_subsample',\\n\",\n",
    "    \")\\n\",\n",
    "    \"rf.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"y_pred_rf = rf.predict(X_test_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Random Forest classification report:')\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_rf, labels=[0, 2, 3]))\\n\",\n",
    "    \"\\n\",\n",
    "    \"cm_rf = confusion_matrix(y_test, y_pred_rf, labels=[0, 2, 3])\\n\",\n",
    "    \"print('RF confusion matrix (rows=true, cols=pred):')\\n\",\n",
    "    \"print(cm_rf)\\n\",\n",
    "    \"\\n\",\n",
    "    \"rf_per_class_acc = {}\\n\",\n",
    "    \"for i, lbl in enumerate([0, 2, 3]):\\n\",\n",
    "    \"    total = cm_rf[i].sum()\\n\",\n",
    "    \"    correct = cm_rf[i, i]\\n\",\n",
    "    \"    acc = 100.0 * correct / total if total > 0 else 0.0\\n\",\n",
    "    \"    rf_per_class_acc[lbl] = acc\\n\",\n",
    "    \"\\n\",\n",
    "    \"rf_per_class_acc\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Experiment 2 \u0013 LSTM (Cloud model)\\n\\n\",\n",
    "    \"We build 24-hour sequences (96 \u0000 15-min blocks) and train an LSTM.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from tensorflow.keras import layers, models\\n\",\n",
    "    \"\\n\",\n",
    "    \"seq_len = 96  # 24 hours at 15-min resolution\\n\",\n",
    "    \"X_train_seq, y_train_seq = make_sequences(df_train, seq_len=seq_len)\\n\",\n",
    "    \"X_val_seq, y_val_seq = make_sequences(df_val, seq_len=seq_len)\\n\",\n",
    "    \"X_test_seq, y_test_seq = make_sequences(df_test, seq_len=seq_len)\\n\",\n",
    "    \"\\n\",\n",
    "    \"n_features = X_train_seq.shape[2]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scale features\\n\",\n",
    "    \"scaler_seq = StandardScaler()\\n\",\n",
    "    \"X_train_2d = X_train_seq.reshape(-1, n_features)\\n\",\n",
    "    \"scaler_seq.fit(X_train_2d)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def scale_seq(X):\\n\",\n",
    "    \"    X2d = X.reshape(-1, n_features)\\n\",\n",
    "    \"    X2d_s = scaler_seq.transform(X2d)\\n\",\n",
    "    \"    return X2d_s.reshape(X.shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train_seq_s = scale_seq(X_train_seq)\\n\",\n",
    "    \"X_val_seq_s = scale_seq(X_val_seq)\\n\",\n",
    "    \"X_test_seq_s = scale_seq(X_test_seq)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Map labels {0,2,3} -> indices {0,1,2}\\n\",\n",
    "    \"unique_labels = sorted(int(v) for v in np.unique(y_train_seq))\\n\",\n",
    "    \"label_to_idx = {lbl: i for i, lbl in enumerate(unique_labels)}\\n\",\n",
    "    \"idx_to_label = {i: lbl for lbl, i in label_to_idx.items()}\\n\",\n",
    "    \"\\n\",\n",
    "    \"map_vec = np.vectorize(label_to_idx.get)\\n\",\n",
    "    \"y_train_m = map_vec(y_train_seq)\\n\",\n",
    "    \"y_val_m = map_vec(y_val_seq)\\n\",\n",
    "    \"y_test_m = map_vec(y_test_seq)\\n\",\n",
    "    \"\\n\",\n",
    "    \"n_classes = len(unique_labels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"inputs = layers.Input(shape=(seq_len, n_features))\\n\",\n",
    "    \"x = layers.Masking(mask_value=0.0)(inputs)\\n\",\n",
    "    \"x = layers.LSTM(64, return_sequences=False)(x)\\n\",\n",
    "    \"x = layers.Dropout(0.3)(x)\\n\",\n",
    "    \"x = layers.Dense(64, activation='relu')(x)\\n\",\n",
    "    \"outputs = layers.Dense(n_classes, activation='softmax')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = models.Model(inputs, outputs)\\n\",\n",
    "    \"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"history = model.fit(\\n\",\n",
    "    \"    X_train_seq_s, y_train_m,\\n\",\n",
    "    \"    validation_data=(X_val_seq_s, y_val_m),\\n\",\n",
    "    \"    epochs=10,\\n\",\n",
    "    \"    batch_size=64,\\n\",\n",
    "    \"    verbose=1,\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_prob_lstm = model.predict(X_test_seq_s)\\n\",\n",
    "    \"y_pred_idx = y_prob_lstm.argmax(axis=1)\\n\",\n",
    "    \"inv_map = np.vectorize(idx_to_label.get)\\n\",\n",
    "    \"y_pred_lstm = inv_map(y_pred_idx)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('LSTM classification report (sequence labels):')\\n\",\n",
    "    \"print(classification_report(y_test_seq, y_pred_lstm, labels=unique_labels))\\n\",\n",
    "    \"\\n\",\n",
    "    \"cm_lstm = confusion_matrix(y_test_seq, y_pred_lstm, labels=unique_labels)\\n\",\n",
    "    \"print('LSTM confusion matrix (rows=true, cols=pred):')\\n\",\n",
    "    \"print(cm_lstm)\\n\",\n",
    "    \"\\n\",\n",
    "    \"lstm_per_class_acc = {}\\n\",\n",
    "    \"for i, lbl in enumerate(unique_labels):\\n\",\n",
    "    \"    total = cm_lstm[i].sum()\\n\",\n",
    "    \"    correct = cm_lstm[i, i]\\n\",\n",
    "    \"    acc = 100.0 * correct / total if total > 0 else 0.0\\n\",\n",
    "    \"    lstm_per_class_acc[lbl] = acc\\n\",\n",
    "    \"\\n\",\n",
    "    \"lstm_per_class_acc\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Side-by-side comparison\\n\\n\",\n",
    "    \"We can now show RF vs LSTM per-class accuracy for labels 0, 2, and 3.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"summary = pd.DataFrame({'RF_acc_%': rf_per_class_acc, 'LSTM_acc_%': lstm_per_class_acc})\\n\",\n",
    "    \"summary\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.x\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n",
    "\n"
   ],
   "id": "631527a5726d4c7"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
